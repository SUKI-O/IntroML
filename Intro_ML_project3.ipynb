{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to ML Project 3\n",
    "## Decision Trees Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_int(df, col_indx):\n",
    "    \"\"\"\n",
    "    Function to convert string value to unique integers in place and return dictionary \n",
    "    Input: df :pd.DataFrame\n",
    "           col_index: column index\n",
    "    output: dictionary: dict to map str : int\n",
    "    \"\"\"\n",
    "    col = df[col_indx]\n",
    "    row = len(col)\n",
    "    keys = pd.unique(df[col_indx])\n",
    "    dictionary = dict(zip(keys, np.linspace(0,len(keys)-1,len(keys),dtype=int)))\n",
    "    for j in range(row):\n",
    "        df[col_indx][j] = dictionary[df[col_indx][j]]\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   0       699 non-null    int64\n",
      " 1   1       699 non-null    int64\n",
      " 2   2       699 non-null    int64\n",
      " 3   3       699 non-null    int64\n",
      " 4   4       699 non-null    int64\n",
      " 5   5       699 non-null    int64\n",
      " 6   6       699 non-null    int64\n",
      " 7   7       699 non-null    int64\n",
      " 8   8       699 non-null    int64\n",
      " 9   9       699 non-null    int64\n",
      "dtypes: int64(10)\n",
      "memory usage: 54.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Breast Cancer (classification)\n",
    "# the last column is the target\n",
    "file_loc = './Data_Set/breast-cancer-wisconsin.data'\n",
    "bc = pd.read_csv(file_loc, header = None)\n",
    "bc = bc.iloc[:, 1:] # dropping 1st column since they are unique identifiers.\n",
    "bc.columns = [i for i in range(len(bc.columns))] #fixing the columns index num\n",
    "#imputing missing values\n",
    "NAs = []\n",
    "for i in range(10):\n",
    "    for j in range(698):\n",
    "        if bc[i][j]== '?':\n",
    "            NAs.append([i,j])\n",
    "bc_vals = bc[5][bc[5]!='?'].astype('int')\n",
    "samples = np.random.choice(bc_vals, 16).copy()\n",
    "for k, i in enumerate(NAs):\n",
    "    bc.iloc[i[1],i[0]] = samples[k]\n",
    "for col in range(bc.shape[1]):        # converting all num to np.int64\n",
    "    bc[col] = bc[col].astype('int64')\n",
    "bc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6\n",
       "0     0  0  0  0  0  0  0\n",
       "1     0  0  0  0  0  1  0\n",
       "2     0  0  0  0  0  2  0\n",
       "3     0  0  0  0  1  0  0\n",
       "4     0  0  0  0  1  1  0\n",
       "...  .. .. .. .. .. .. ..\n",
       "1723  3  3  3  2  1  1  3\n",
       "1724  3  3  3  2  1  2  2\n",
       "1725  3  3  3  2  2  0  0\n",
       "1726  3  3  3  2  2  1  3\n",
       "1727  3  3  3  2  2  2  2\n",
       "\n",
       "[1728 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# car (classification)\n",
    "# the last column is the target (6)\n",
    "file_loc = './Data_Set/car.data'\n",
    "car = pd.read_csv(file_loc, header = None)\n",
    "[str_to_int(car, i) for i in range(7)] # converting string to integer\n",
    "for col in range(car.shape[1]):        # converting all num to np.int64\n",
    "    car[col] = car[col].astype('int64')\n",
    "car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-346e83ab41dd>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col_indx][j] = dictionary[df[col_indx][j]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.062963</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>6.185185</td>\n",
       "      <td>7.333334</td>\n",
       "      <td>7.666666</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>4.444445</td>\n",
       "      <td>-7.888889</td>\n",
       "      <td>7.777778</td>\n",
       "      <td>0.545635</td>\n",
       "      <td>-1.121818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>6.666666</td>\n",
       "      <td>8.333334</td>\n",
       "      <td>7.777778</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>-8.333333</td>\n",
       "      <td>8.444445</td>\n",
       "      <td>0.538580</td>\n",
       "      <td>-0.924817</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.107407</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>6.111111</td>\n",
       "      <td>7.555555</td>\n",
       "      <td>7.222222</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>4.333334</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>-7.666666</td>\n",
       "      <td>7.555555</td>\n",
       "      <td>0.532628</td>\n",
       "      <td>-0.965946</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.474074</td>\n",
       "      <td>5.851852</td>\n",
       "      <td>7.777778</td>\n",
       "      <td>6.444445</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>5.777778</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>-7.555555</td>\n",
       "      <td>7.777778</td>\n",
       "      <td>0.573633</td>\n",
       "      <td>-0.744272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.374074</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.429629</td>\n",
       "      <td>6.037037</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.666666</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>4.888889</td>\n",
       "      <td>-7.777778</td>\n",
       "      <td>7.888889</td>\n",
       "      <td>0.562919</td>\n",
       "      <td>-1.175773</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>36.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>1.851851</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.711110</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>9.888889</td>\n",
       "      <td>12.111111</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>-10.333333</td>\n",
       "      <td>-3.666667</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.452229</td>\n",
       "      <td>2.368310</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>186.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.655555</td>\n",
       "      <td>13.703704</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>17.777779</td>\n",
       "      <td>-9.111111</td>\n",
       "      <td>-3.111111</td>\n",
       "      <td>12.222222</td>\n",
       "      <td>17.777779</td>\n",
       "      <td>0.401347</td>\n",
       "      <td>2.382683</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>197.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>2.444444</td>\n",
       "      <td>6.829628</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>7.599998</td>\n",
       "      <td>16.074074</td>\n",
       "      <td>13.111111</td>\n",
       "      <td>16.666668</td>\n",
       "      <td>18.444445</td>\n",
       "      <td>-8.888889</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>7.111111</td>\n",
       "      <td>18.555555</td>\n",
       "      <td>0.292729</td>\n",
       "      <td>2.789800</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>208.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1.055556</td>\n",
       "      <td>0.862963</td>\n",
       "      <td>2.444444</td>\n",
       "      <td>5.007407</td>\n",
       "      <td>14.148149</td>\n",
       "      <td>10.888889</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>18.555555</td>\n",
       "      <td>-9.777778</td>\n",
       "      <td>-3.444444</td>\n",
       "      <td>13.222222</td>\n",
       "      <td>18.555555</td>\n",
       "      <td>0.421621</td>\n",
       "      <td>2.392487</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>223.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.349603</td>\n",
       "      <td>2.388889</td>\n",
       "      <td>2.080776</td>\n",
       "      <td>12.962963</td>\n",
       "      <td>11.555555</td>\n",
       "      <td>9.777778</td>\n",
       "      <td>17.555555</td>\n",
       "      <td>-4.222222</td>\n",
       "      <td>-9.555555</td>\n",
       "      <td>13.777778</td>\n",
       "      <td>17.555555</td>\n",
       "      <td>0.445418</td>\n",
       "      <td>1.838850</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1         2         3         4         5          6   \\\n",
       "0    140.0  125.0  0.277778  0.062963  0.666667  0.311111   6.185185   \n",
       "1    188.0  133.0  0.333333  0.266667  0.500000  0.077778   6.666666   \n",
       "2    105.0  139.0  0.277778  0.107407  0.833333  0.522222   6.111111   \n",
       "3     34.0  137.0  0.500000  0.166667  1.111111  0.474074   5.851852   \n",
       "4     39.0  111.0  0.722222  0.374074  0.888889  0.429629   6.037037   \n",
       "..     ...    ...       ...       ...       ...       ...        ...   \n",
       "205   36.0  243.0  1.888889  1.851851  2.000000  0.711110  13.333333   \n",
       "206  186.0  218.0  1.166667  0.744444  1.166667  0.655555  13.703704   \n",
       "207  197.0  236.0  2.444444  6.829628  3.333333  7.599998  16.074074   \n",
       "208  208.0  240.0  1.055556  0.862963  2.444444  5.007407  14.148149   \n",
       "209  223.0  185.0  0.500000  0.349603  2.388889  2.080776  12.962963   \n",
       "\n",
       "            7          8          9          10        11         12  \\\n",
       "0     7.333334   7.666666   3.555556   3.444444  4.444445  -7.888889   \n",
       "1     8.333334   7.777778   3.888889   5.000000  3.333333  -8.333333   \n",
       "2     7.555555   7.222222   3.555556   4.333334  3.333333  -7.666666   \n",
       "3     7.777778   6.444445   3.333333   5.777778  1.777778  -7.555555   \n",
       "4     7.000000   7.666666   3.444444   2.888889  4.888889  -7.777778   \n",
       "..         ...        ...        ...        ...       ...        ...   \n",
       "205   9.888889  12.111111  18.000000 -10.333333 -3.666667  14.000000   \n",
       "206  10.666667  12.666667  17.777779  -9.111111 -3.111111  12.222222   \n",
       "207  13.111111  16.666668  18.444445  -8.888889  1.777778   7.111111   \n",
       "208  10.888889  13.000000  18.555555  -9.777778 -3.444444  13.222222   \n",
       "209  11.555555   9.777778  17.555555  -4.222222 -9.555555  13.777778   \n",
       "\n",
       "            13        14        15  16  \n",
       "0     7.777778  0.545635 -1.121818   0  \n",
       "1     8.444445  0.538580 -0.924817   0  \n",
       "2     7.555555  0.532628 -0.965946   0  \n",
       "3     7.777778  0.573633 -0.744272   0  \n",
       "4     7.888889  0.562919 -1.175773   0  \n",
       "..         ...       ...       ...  ..  \n",
       "205  18.000000  0.452229  2.368310   6  \n",
       "206  17.777779  0.401347  2.382683   6  \n",
       "207  18.555555  0.292729  2.789800   6  \n",
       "208  18.555555  0.421621  2.392487   6  \n",
       "209  17.555555  0.445418  1.838850   6  \n",
       "\n",
       "[210 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#segmentation (classification)\n",
    "file_loc = './Data_Set/segmentation.data'\n",
    "segmentation = pd.read_csv(file_loc, skiprows=[0,1,2,3,4], header=None)\n",
    "str_to_int(segmentation, 0)\n",
    "\n",
    "# col 3 is all identical and has no info. will frop this\n",
    "segmentation.drop([3,4,5], axis= 1, inplace=True)\n",
    "target = segmentation[0]\n",
    "segmentation = pd.concat([segmentation.iloc[:,1:],target], axis = 1)\n",
    "segmentation.columns = [i for i in range(segmentation.shape[1])]\n",
    "segmentation.iloc[:,16] = segmentation.iloc[:,16].astype(int)\n",
    "segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_validation (stratefied) 5 fold:\n",
    "def stratefied_cross_validation(df, target, k_fold = 5):\n",
    "    \"\"\"\n",
    "    Function to split data for stratefied k-fold cv testing \n",
    "    where each group have same class representation, plus 10% validation set\n",
    "    Input: original data, target feature id\n",
    "    Output:'indeces' of stratefied k-fold cv sets, and tuning set \n",
    "    \"\"\"\n",
    "    N = len(df)\n",
    "    index = [index for index in df.index]\n",
    "    np.random.shuffle(index)\n",
    "    validation_set = index[:int(N/10)]\n",
    "    remain= index[int(N/10):]\n",
    "    # among the remain, group the data into each classifications\n",
    "    k_splits = [[] for _ in range(k_fold)]\n",
    "    classes = np.unique(df[target])\n",
    "    for c in classes:\n",
    "        group = [idx for idx in remain if df.iloc[idx,target]==c]\n",
    "        np.random.shuffle(group)\n",
    "        group_k_splits = np.array_split(group, k_fold)\n",
    "        np.random.shuffle(group_k_splits)\n",
    "        for k in range(k_fold):\n",
    "            holdout = group_k_splits[k]\n",
    "            np.random.shuffle(holdout)\n",
    "            k_splits[k].extend(holdout)\n",
    "            \n",
    "    return k_splits, validation_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper to generate dataset from index list\n",
    "def k_fold_cv_sets(k_splits):\n",
    "    \"\"\" \n",
    "    Based on the k_splits indices, returns 1 hold out set for testing\n",
    "    and the rest for training\n",
    "    Output: k sets of (train_set, test_set)\n",
    "    \"\"\"\n",
    "    k_fold = len(k_splits)\n",
    "    k_fold_idx = []\n",
    "    for k in range(k_fold):\n",
    "        test_set = k_splits[k]\n",
    "        training_idx = [i for i in range(k_fold) if i !=k]\n",
    "        train_set = []\n",
    "        for i in training_idx:\n",
    "            train_set.extend(k_splits[i])\n",
    "        k_fold_idx.append((train_set, test_set))\n",
    "    return k_fold_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(test_y, y_hats):\n",
    "    \"\"\"\n",
    "    Input: data_y, true value vector, y_hat, prediction vector\n",
    "    Output: accuracy as number of correct prediction/ total population\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    N = len(test_y)\n",
    "    for i in range(len(test_y)):\n",
    "        correct += test_y[i] == y_hats[i]\n",
    "    return correct/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrophy(df, feature):\n",
    "    \"\"\"\n",
    "    Input: df: pd.DataFrame\n",
    "           feature: feature id\n",
    "    Output: entropy of given DataFrame based on the seleced feature\n",
    "    \"\"\"\n",
    "    if len(df)<=1:\n",
    "        return 0\n",
    "    classes = pd.unique(df[feature])\n",
    "    p = df[feature].value_counts().values/len(df[feature])\n",
    "    return -sum(p*np.log2(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuous(df, feature):\n",
    "    \"\"\"\n",
    "    Input: df: pd.DataFrame\n",
    "           feature: feature id ( column num)\n",
    "    Output: returns True if the feature is continuous, False if descrete\n",
    "    \"\"\"\n",
    "    if df[feature].any:\n",
    "        if (df[feature].dtype == 'int64')or(df[feature].dtype == 'int32'):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_label(df, target, regression = False):\n",
    "    \"\"\"\n",
    "    Input: df: pd.DataFrame\n",
    "           target: target id\n",
    "    Output: returns the most commonly present target label for classification\n",
    "            return the mean of target values for continuous values.\n",
    "    \"\"\"\n",
    "    if regression:\n",
    "        # if target is continuous take the mean\n",
    "        label = np.mean(df[target])\n",
    "    else:\n",
    "        # if target is descrete valuestake the plural voting\n",
    "        label = df[target].value_counts(ascending=False).keys()[0]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Calculations Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_entrophy(df, feature, target,tol=1e-4, binary_split=False):\n",
    "    \"\"\"\n",
    "    Input: df, pd.DataFrame\n",
    "           feature: feature id\n",
    "           feature_val: feature value\n",
    "           binary_split: default None, used as threshold to binary split\n",
    "    Output: entropy after DataFrame was split on the given feature value\n",
    "            information value for the feature being concidered\n",
    "    \"\"\"\n",
    "    MAX = float('inf')\n",
    "    \n",
    "    def partial_entrophy(df,subset, target):\n",
    "         return (len(subset)/len(df))*entrophy(subset, target)\n",
    "    \n",
    "    def partial_information_value(df, subset):\n",
    "        # if this partition create no subset, no information value left\n",
    "        if (len(subset)==0) | (len(df)==0):\n",
    "            return 0  \n",
    "        else:\n",
    "            p = len(subset)/len(df)\n",
    "            return -p*np.log2(p)\n",
    "    \n",
    "    binary_split = continuous(df, feature)\n",
    "    best_split_point = None\n",
    "    information_value = 0\n",
    "    \n",
    "    if binary_split == False:  # for descrete value\n",
    "\n",
    "        feature_vals = np.sort(df[feature].unique())\n",
    "        post_split_entrophy = 0\n",
    "        information_value = 0\n",
    "        for feature_val in feature_vals:\n",
    "            subset = df[df[feature]==feature_val]\n",
    "            post_split_entrophy += partial_entrophy(df,subset, target)\n",
    "            information_value += partial_information_value(df, subset)\n",
    "            \n",
    "    else:  # for continuous value\n",
    "        MIN_entrophy = MAX       \n",
    "        df_sorted = df.sort_values(by=feature)\n",
    "        index = df_sorted.index\n",
    "        for i in range(len(index)-1):\n",
    "            split_point = df_sorted[feature][index[i]]\n",
    "            \n",
    "            if df_sorted[target][index[i]]!= df_sorted[target][index[i+1]]:\n",
    "                \n",
    "                entrophy_at_split_i = 0\n",
    "                information_value_i = 0\n",
    "                \n",
    "                # get partial entrophy for left of the split\n",
    "                subset_L = df_sorted[df_sorted[feature]<split_point]\n",
    "                information_value += partial_information_value(df, subset_L)\n",
    "                entrophy_at_split_i+= partial_entrophy(df,subset_L, target)\n",
    "                \n",
    "                # get partial entrophy for right of the split\n",
    "                subset_R = df_sorted[df_sorted[feature]>=split_point]\n",
    "                information_value_i += partial_information_value(df, subset_R)\n",
    "                entrophy_at_split_i+= partial_entrophy(df,subset_R, target)\n",
    "                \n",
    "                if entrophy_at_split_i < MIN_entrophy:\n",
    "                    MIN_entrophy = entrophy_at_split_i  \n",
    "                    best_split_point = split_point\n",
    "                    information_value = information_value_i\n",
    "                    \n",
    "        post_split_entrophy = MIN_entrophy \n",
    "        \n",
    "    return post_split_entrophy, information_value, best_split_point\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitFeature(df, target):\n",
    "    \"\"\"\n",
    "    Input: df: pd.DataFrame\n",
    "           target: target id\n",
    "    Output: returns col index of the highest post_split_entrophy\n",
    "    \"\"\"\n",
    "    features = [col for col  in df.columns if col!=target]\n",
    "    best_feature = None\n",
    "    best_gain_ratio = float('inf')\n",
    "    best_split = None\n",
    "    pre_split_entrophy = entrophy(df, target) # entrophy before the split\n",
    "    \n",
    "    if len(features) == 0:\n",
    "        return best_feature, best_gain_ratio, best_split\n",
    "\n",
    "    for feature in features:\n",
    "        post_split_entrophy, information_value, best_split_point = split_entrophy(df, feature, target, continuous(df, feature))\n",
    "        gain = pre_split_entrophy - post_split_entrophy\n",
    "        gain_ratio = gain/information_value\n",
    "        if gain_ratio < best_gain_ratio:\n",
    "            best_feature = feature\n",
    "            best_gain_ratio = gain_ratio\n",
    "            best_split = best_split_point\n",
    "    \n",
    "    return best_feature, best_gain_ratio, best_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node and Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node class for tree building\n",
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        self.label = None\n",
    "        self.feature = None \n",
    "        self.feature_values = []\n",
    "        self.bin = []\n",
    "        self.split_point = None\n",
    "        self.parent = self\n",
    "        #self.parent_feature = None\n",
    "        #self.parent_feature_value = None\n",
    "        self.isLeaf = False\n",
    "        self.pruned = False  # for Pruning \n",
    "        self.gain_ratio = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree building\n",
    "def ID3(df, target, tol= 1e-4):\n",
    "    node = Node()\n",
    "    node.label = most_common_label(df,target)\n",
    "    node.bin = df.iloc[:,target]\n",
    "    features = [col for col  in df.columns if col!=target]\n",
    "\n",
    "    if (len(df.iloc[:,target].unique())<=1):  # if the node is pure, return node\n",
    "        node.label = most_common_label(df,target)\n",
    "        node.isLeaf = True\n",
    "        return node\n",
    "\n",
    "    best_feature, best_gain_ratio, best_split = splitFeature(df, target)\n",
    "    \n",
    "    node.feature = best_feature\n",
    "    node.gain_ratio = best_gain_ratio\n",
    "    node.split_point = best_split\n",
    "    \n",
    "    if best_feature == None: #there is no feature to split on. The node is already pure.\n",
    "        #node.feature = node.parent.feature # the best feature be the one that was used by the parent\n",
    "        node.label = most_common_label(df,target)\n",
    "        node.isLeaf = True\n",
    "        return node\n",
    "\n",
    "    if continuous(df, best_feature): \n",
    "        # for binary split, L= 0, R= 1\n",
    "        node.feature_values = [0, 1]\n",
    "        subset_L = df[df[best_feature]< best_split]\n",
    "        subset_R = df[df[best_feature]>= best_split]\n",
    "        \n",
    "        if subset_L.empty or subset_R.empty:\n",
    "            # if nothing is less than the split point, take the median of the whole set\n",
    "            node.label = most_common_label(df,target)\n",
    "            node.isLeaf = True\n",
    "            return node\n",
    "        \n",
    "        elif len(subset_L)<=1:\n",
    "            node.label = most_common_label(subset_L,target)\n",
    "            node.isLeaf = True\n",
    "            return node\n",
    "        \n",
    "        elif len(subset_R)<=1:\n",
    "            node.label = most_common_label(subset_R,target)\n",
    "            node.isLeaf = True\n",
    "            return node\n",
    "        \n",
    "        else:\n",
    "            child_L = ID3(subset_L, target)\n",
    "            child_L.bin = subset_L.iloc[:,target]\n",
    "            child_L.parent = node\n",
    "            node.children[0] = child_L\n",
    "            child_R = ID3(subset_R, target)\n",
    "            child_R.bin = subset_R.iloc[:,target]\n",
    "            child_R.parent = node\n",
    "            node.children[1] = child_R\n",
    "        return node\n",
    "\n",
    "    else:\n",
    "        node.feature_values = df[best_feature].unique()  # all class labels\n",
    "        for feature_val in node.feature_values:\n",
    "            subset = df[df[best_feature]==feature_val]\n",
    "            child = ID3(subset, target)\n",
    "            child.parent = node\n",
    "            child.bin = subset.iloc[:,target]\n",
    "            node.children[feature_val] = child    \n",
    "\n",
    "        return node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(node, df, sample, target, continuous_val = False):\n",
    "    \"\"\"\n",
    "    This function takes input and traverse through the DT starting at the root and returns the\\\n",
    "    leaf if reached, if not take the most common value at the last node reached. \n",
    "    For node \n",
    "    Input: trained DT root node\n",
    "           target: target id\n",
    "           sample to be predicted\n",
    "    Output: prediction\n",
    "    \"\"\"\n",
    "    if node.isLeaf:\n",
    "        # if node is a leaf and not pruned,return its label\n",
    "        return node.label\n",
    "            \n",
    "    # for continuous value\n",
    "    if continuous(df, node.feature):           \n",
    "        if (sample[node.feature] < node.split_point) and (node.children[0].pruned == False):\n",
    "            return predict(node.children[0], df, sample, target)\n",
    "        elif (sample[node.feature] >= node.split_point) and (node.children[1].pruned == False):\n",
    "            return predict(node.children[1], df, sample, target)\n",
    "        else:\n",
    "            return node.label\n",
    "        \n",
    "    #for discrete feature values\n",
    "    else:\n",
    "        #if the children exsist and is not pruned\n",
    "        if (sample[node.feature] in node.children) and (node.children[int(sample[node.feature])].pruned== False): \n",
    "                # go down further down the tree \n",
    "                return predict(node.children[sample[node.feature]], df, sample, target)\n",
    "        else:\n",
    "            # if the children node does not have the sample value, or is pruned return the current label\n",
    "            return node.label\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ID3_cross_validation_test(df, target, prune = True, score = accuracy , k= 5):\n",
    "    \"\"\"\n",
    "    This function conducts stratefied k-hold cv tes\n",
    "    Input:\n",
    "        data_X : matrix, model feature set\n",
    "        target:target feature id\n",
    "        score: evaluation function\n",
    "    Out:\n",
    "        average score over k-folds\n",
    "    \"\"\"\n",
    "    k_splits, validation_set = stratefied_cross_validation(df, target, k_fold = k)\n",
    "    k_fold_idx = k_fold_cv_sets(k_splits)\n",
    "    unpruned = []\n",
    "    pruned = []\n",
    "    for i in range(k):\n",
    "        train_idx, test_idx =  k_fold_idx[i]\n",
    "        train_X= df.iloc[train_idx]\n",
    "        test_y = df.iloc[test_idx][target].values\n",
    "        y_hats = []\n",
    "        node = ID3(train_X, target) # build DT\n",
    "        # test for unpruned tree\n",
    "        for test_id in test_idx:\n",
    "            sample = df.iloc[test_id, :]\n",
    "            y_hats.append(predict(node, df, sample, target))\n",
    "        unpruned.append(score(list(test_y), list(y_hats)))\n",
    "        if prune:\n",
    "            prune_tree(node, validation_set, df, target, score)\n",
    "            for test_id in test_idx:\n",
    "                sample = df.iloc[test_id, :]\n",
    "                y_hats.append(predict(node, df, sample, target))\n",
    "                pruned.append(score(list(test_y), list(y_hats)))\n",
    "            return np.mean(unpruned), np.mean(pruned)\n",
    "        \n",
    "    return np.mean(unpruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = bc\n",
    "target = 9\n",
    "k_splits, validation_set = stratefied_cross_validation(df, target, k_fold = k)\n",
    "k_fold_idx = k_fold_cv_sets(k_splits)\n",
    "\n",
    "i = 0\n",
    "train_idx, test_idx =  k_fold_idx[i]\n",
    "train_X= df.iloc[train_idx]\n",
    "test_y = df.iloc[test_idx][target].values\n",
    "print(test_y)\n",
    "df.iloc[test_idx, target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = None\n",
    "def prune_tree(node, validation_set, df, target, score = accuracy):\n",
    "    \"\"\"\n",
    "    Conduct pruning based on test score using validation set. \n",
    "    If score improves with pruning a leaf node, it will be pruned, o.w. kept. \n",
    "    \"\"\"\n",
    "    #tree = copy.deepcopy(node)\n",
    "    global tree\n",
    "    tree = node\n",
    "    def prune_test(node,validation_set, df, target, score = accuracy):\n",
    "        \"\"\"\n",
    "        conduct sub_test for pre, post pruning\n",
    "        \"\"\"\n",
    "        y_hats = []\n",
    "        test_y = df[target][validation_set].values\n",
    "        for val_id in validation_set:\n",
    "            sample = df.iloc[val_id]\n",
    "            y_hats.append(predict(node, df, sample, target))\n",
    "        test_score = score(list(test_y), list(y_hats))\n",
    "        return test_score\n",
    "    \n",
    "    def prune_node(node, validation_set, df, target, score):\n",
    "        if node.isLeaf:\n",
    "            #try pruning\n",
    "            pre_pruning_test = prune_test(tree,validation_set, df, target, score = score)\n",
    "            node.pruned = True # mark the node pruned\n",
    "            node.parent.isLeaf = True # make its parent a leaf\n",
    "            post_pruning_test = prune_test(tree,validation_set, df, target, score = score)\n",
    "            if pre_pruning_test >= post_pruning_test:\n",
    "                node.pruned = False # don't prune this node \n",
    "                node.parent.isLeaf = False\n",
    "            return\n",
    "        \n",
    "        children = [child for child in node.children.values()]\n",
    "        for child in children:\n",
    "            prune_node(child, validation_set, df, target, score = accuracy)\n",
    "        \n",
    "        pre_pruning_test = prune_test(tree,validation_set, df, target, score = score)\n",
    "        node.pruned = True # mark the node pruned\n",
    "        node.parent.isLeaf = True # make its parent a leaf\n",
    "        post_pruning_test = prune_test(tree,validation_set, df, target, score = score)\n",
    "        if pre_pruning_test >= post_pruning_test:\n",
    "            node.pruned = False\n",
    "            node.parent.isLeaf = False\n",
    "    \n",
    "    prune_node(tree, validation_set, df, target, score)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = car\n",
    "target = 6\n",
    "k_splits, validation_set = stratefied_cross_validation(df, target,k_fold= 5)\n",
    "k_fold_idx = k_fold_cv_sets(k_splits)\n",
    "i = 0\n",
    "train_idx, test_idx =  k_fold_idx[i]\n",
    "train_X= df.iloc[train_idx]\n",
    "test_y = df.iloc[test_idx][target].values\n",
    "y_hats = []\n",
    "#node = ID3(df, target) # build DT\n",
    "\n",
    "#ID3_cross_validation_test(df, target, prune=True, score = accuracy, k =1 )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs(node):\n",
    "    global pruned\n",
    "    global unprunedd\n",
    "    if node.isLeaf and node.pruned:\n",
    "        pruned +=1\n",
    "        print('pruned')\n",
    "    if node.isLeaf and node.pruned==False:\n",
    "        print('unpruned')\n",
    "        unpruned +=1\n",
    "    else:\n",
    "        children = [child for child in node.children.values()]\n",
    "        for child in children:\n",
    "            dfs(child)\n",
    "    print(pruned, unpruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-9bb55841cdc5>:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  gain_ratio = gain/information_value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.873015873015873, 0.8730158730158734)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = bc\n",
    "target = 9\n",
    "ID3_cross_validation_test(df, target, prune= True, score = accuracy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-9bb55841cdc5>:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  gain_ratio = gain/information_value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6838135872701788"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = car\n",
    "target = 6\n",
    "ID3_cross_validation_test(df, target, prune=False, score = accuracy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-7a9e88d90747>:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  gain_ratio = gain/information_value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20872769241190295"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = segmentation\n",
    "target= 16\n",
    "#node = ID3(df, target)\n",
    "ID3_cross_validation_test(df, target, prune=False, score = accuracy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-9bb55841cdc5>:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  gain_ratio = gain/information_value\n"
     ]
    }
   ],
   "source": [
    "df = car\n",
    "target = 6\n",
    "k_splits, validation_set = stratefied_cross_validation(df, target, k_fold = k)\n",
    "k_fold_idx = k_fold_cv_sets(k_splits)\n",
    "i = 0\n",
    "train_idx, test_idx =  k_fold_idx[i]\n",
    "train_X= df.iloc[train_idx]\n",
    "test_y = df.iloc[test_idx,target].values\n",
    "train_y = df.iloc[train_idx, target].values\n",
    "node_car = ID3(train_X, target, tol=1) # build DT\n",
    "# test for unpruned tree\n",
    "for test_id in test_idx:\n",
    "    sample = df.iloc[test_id, :]\n",
    "    y_hats.append(predict(node_car, df, sample, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'no' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-49dddb3b048c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mno\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'no' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
